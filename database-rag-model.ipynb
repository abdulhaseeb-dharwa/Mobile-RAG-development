{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import sqlite3\nimport pandas as pd\nimport numpy as np\nimport os\nimport json\nimport re\nfrom typing import Dict, List, Tuple, Optional, Union\nimport logging","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-05-06T15:01:08.972569Z","iopub.execute_input":"2025-05-06T15:01:08.972889Z","iopub.status.idle":"2025-05-06T15:01:08.977273Z","shell.execute_reply.started":"2025-05-06T15:01:08.972866Z","shell.execute_reply":"2025-05-06T15:01:08.976489Z"}},"outputs":[],"execution_count":83},{"cell_type":"code","source":"# For LLM interaction - using Anthropic's Claude API\n# For Kaggle testing, we'll use an API-based approach\nimport requests\nfrom requests.adapters import HTTPAdapter\nfrom requests.packages.urllib3.util.retry import Retry","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-06T15:01:08.992652Z","iopub.execute_input":"2025-05-06T15:01:08.993211Z","iopub.status.idle":"2025-05-06T15:01:08.996481Z","shell.execute_reply.started":"2025-05-06T15:01:08.993192Z","shell.execute_reply":"2025-05-06T15:01:08.995789Z"}},"outputs":[],"execution_count":84},{"cell_type":"code","source":"# Set up logging\nlogging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\nlogger = logging.getLogger(__name__)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-06T15:01:09.001477Z","iopub.execute_input":"2025-05-06T15:01:09.002075Z","iopub.status.idle":"2025-05-06T15:01:09.009298Z","shell.execute_reply.started":"2025-05-06T15:01:09.002052Z","shell.execute_reply":"2025-05-06T15:01:09.008716Z"}},"outputs":[],"execution_count":85},{"cell_type":"code","source":"#####################################################\n# Database Schema Management\n#####################################################\n\nclass DatabaseSchemaManager:\n    \"\"\"Manages the extraction and representation of SQLite database schema.\"\"\"\n    \n    def __init__(self, db_path: str):\n        \"\"\"\n        Initialize with path to SQLite database.\n        \n        Args:\n            db_path: Path to the SQLite database file\n        \"\"\"\n        self.db_path = db_path\n        self.connection = None\n        self.schema_cache = None\n    \n    def connect(self) -> None:\n        \"\"\"Establish connection to the database.\"\"\"\n        try:\n            self.connection = sqlite3.connect(self.db_path)\n            logger.info(f\"Connected to database at {self.db_path}\")\n        except sqlite3.Error as e:\n            logger.error(f\"Error connecting to database: {e}\")\n            raise\n    \n    def close(self) -> None:\n        \"\"\"Close the database connection.\"\"\"\n        if self.connection:\n            self.connection.close()\n            self.connection = None\n            logger.info(\"Database connection closed\")\n    \n    def get_schema(self, refresh: bool = False) -> Dict:\n        \"\"\"\n        Extract database schema information.\n        \n        Args:\n            refresh: Whether to refresh the schema cache\n            \n        Returns:\n            Dictionary containing the database schema\n        \"\"\"\n        if self.schema_cache is not None and not refresh:\n            return self.schema_cache\n        \n        if not self.connection:\n            self.connect()\n        \n        schema = {\n            \"tables\": [],\n            \"relationships\": []\n        }\n        \n        # Get all tables\n        try:\n            cursor = self.connection.cursor()\n            cursor.execute(\"SELECT name FROM sqlite_master WHERE type='table' AND name NOT LIKE 'sqlite_%';\")\n            tables = cursor.fetchall()\n            \n            for table in tables:\n                table_name = table[0]\n                table_info = {\n                    \"name\": table_name,\n                    \"columns\": []\n                }\n                \n                # Get column information\n                cursor.execute(f\"PRAGMA table_info('{table_name}');\")\n                columns = cursor.fetchall()\n                \n                for column in columns:\n                    col_id, col_name, col_type, not_null, default_val, is_pk = column\n                    table_info[\"columns\"].append({\n                        \"name\": col_name,\n                        \"type\": col_type,\n                        \"is_primary_key\": bool(is_pk),\n                        \"not_null\": bool(not_null),\n                        \"default\": default_val\n                    })\n                \n                schema[\"tables\"].append(table_info)\n            \n            # Get foreign key relationships\n            for table in tables:\n                table_name = table[0]\n                cursor.execute(f\"PRAGMA foreign_key_list('{table_name}');\")\n                foreign_keys = cursor.fetchall()\n                \n                for fk in foreign_keys:\n                    id, seq, ref_table, from_col, to_col, on_update, on_delete, match = fk\n                    schema[\"relationships\"].append({\n                        \"table\": table_name,\n                        \"column\": from_col,\n                        \"references_table\": ref_table,\n                        \"references_column\": to_col\n                    })\n            \n            self.schema_cache = schema\n            logger.info(f\"Extracted schema with {len(schema['tables'])} tables\")\n            return schema\n            \n        except sqlite3.Error as e:\n            logger.error(f\"Error extracting schema: {e}\")\n            raise\n    \n    def format_schema_for_llm(self) -> str:\n        \"\"\"\n        Format the database schema in a way that's optimal for LLM understanding.\n        \n        Returns:\n            String representation of the schema formatted for the LLM\n        \"\"\"\n        schema = self.get_schema()\n        formatted_schema = \"DATABASE SCHEMA:\\n\\n\"\n        \n        # Format tables and columns\n        for table in schema[\"tables\"]:\n            formatted_schema += f\"Table: {table['name']}\\n\"\n            formatted_schema += \"Columns:\\n\"\n            \n            for column in table[\"columns\"]:\n                pk_marker = \" (PRIMARY KEY)\" if column[\"is_primary_key\"] else \"\"\n                null_marker = \" NOT NULL\" if column[\"not_null\"] else \"\"\n                formatted_schema += f\"  - {column['name']} ({column['type']}){pk_marker}{null_marker}\\n\"\n            \n            formatted_schema += \"\\n\"\n        \n        # Format relationships\n        if schema[\"relationships\"]:\n            formatted_schema += \"Relationships:\\n\"\n            for rel in schema[\"relationships\"]:\n                formatted_schema += f\"  - {rel['table']}.{rel['column']} -> {rel['references_table']}.{rel['references_column']}\\n\"\n        \n        return formatted_schema\n\n    def get_sample_data(self, limit: int = 3) -> Dict[str, pd.DataFrame]:\n        \"\"\"\n        Get sample data from each table for better LLM understanding.\n        \n        Args:\n            limit: Number of sample rows to fetch\n            \n        Returns:\n            Dictionary mapping table names to DataFrames with sample data\n        \"\"\"\n        if not self.connection:\n            self.connect()\n        \n        schema = self.get_schema()\n        samples = {}\n        \n        for table in schema[\"tables\"]:\n            table_name = table[\"name\"]\n            try:\n                query = f\"SELECT * FROM {table_name} LIMIT {limit};\"\n                samples[table_name] = pd.read_sql_query(query, self.connection)\n                logger.info(f\"Fetched {len(samples[table_name])} sample rows from {table_name}\")\n            except sqlite3.Error as e:\n                logger.warning(f\"Could not fetch sample data from {table_name}: {e}\")\n                samples[table_name] = pd.DataFrame()\n        \n        return samples\n    \n    def format_sample_data_for_llm(self, limit: int = 3) -> str:\n        \"\"\"\n        Format sample data in a way that's optimal for LLM understanding.\n        \n        Args:\n            limit: Number of sample rows to fetch\n            \n        Returns:\n            String representation of sample data formatted for the LLM\n        \"\"\"\n        samples = self.get_sample_data(limit)\n        formatted_samples = \"SAMPLE DATA:\\n\\n\"\n        \n        for table_name, data in samples.items():\n            formatted_samples += f\"Table: {table_name}\\n\"\n            \n            if data.empty:\n                formatted_samples += \"  (No data available)\\n\\n\"\n                continue\n            \n            # Convert DataFrame to string representation with proper formatting\n            table_str = data.to_string(index=False)\n            # Add indentation to each line\n            table_str = \"\\n\".join(\"  \" + line for line in table_str.split(\"\\n\"))\n            formatted_samples += f\"{table_str}\\n\\n\"\n        \n        return formatted_samples","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-06T15:01:09.011673Z","iopub.execute_input":"2025-05-06T15:01:09.012086Z","iopub.status.idle":"2025-05-06T15:01:09.029485Z","shell.execute_reply.started":"2025-05-06T15:01:09.012069Z","shell.execute_reply":"2025-05-06T15:01:09.028819Z"}},"outputs":[],"execution_count":86},{"cell_type":"code","source":"#####################################################\n# Query Processing\n#####################################################\n\nclass QueryProcessor:\n    \"\"\"Processes natural language queries and converts them to SQL.\"\"\"\n    \n    def __init__(self, llm_client, schema_manager: DatabaseSchemaManager):\n        \"\"\"\n        Initialize with an LLM client and schema manager.\n        \n        Args:\n            llm_client: Client for LLM API interaction\n            schema_manager: Database schema manager instance\n        \"\"\"\n        self.llm_client = llm_client\n        self.schema_manager = schema_manager\n    \n    def process_query(self, user_query: str) -> Dict:\n        \"\"\"\n        Process a natural language query to generate SQL.\n        \n        Args:\n            user_query: Natural language query from the user\n            \n        Returns:\n            Dictionary containing SQL query and explanation\n        \"\"\"\n        # Get formatted schema for the LLM\n        schema_info = self.schema_manager.format_schema_for_llm()\n        sample_data = self.schema_manager.format_sample_data_for_llm(limit=2)\n        \n        # Create prompt for the LLM\n        prompt = self._create_sql_generation_prompt(user_query, schema_info, sample_data)\n        \n        # Get response from LLM\n        response = self.llm_client.generate_sql(prompt)\n        \n        # Extract SQL and explanation from LLM response\n        result = self._parse_llm_response(response)\n        logger.info(f\"Generated SQL: {result['sql']}\")\n        \n        return result\n    \n    def _create_sql_generation_prompt(self, user_query: str, schema_info: str, sample_data: str) -> str:\n        \"\"\"\n        Create a prompt for SQL generation.\n        \n        Args:\n            user_query: User's natural language query\n            schema_info: Formatted database schema information\n            sample_data: Formatted sample data\n            \n        Returns:\n            Formatted prompt for the LLM\n        \"\"\"\n        prompt = f\"\"\"\n        You are an AI assistant that converts natural language queries into SQLite SQL queries.\n        Given the following database schema and sample data, generate a SQL query that answers the user's question.\n        \n        {schema_info}\n        \n        {sample_data}\n        \n        USER QUESTION: {user_query}\n        \n        Please respond in the following format:\n        ```sql\n        -- Your SQL query here\n        ```\n        \n        EXPLANATION:\n        Explain your approach and how your SQL query answers the user's question.\n        \n        Make sure your SQL query:\n        1. Is valid SQLite syntax\n        2. References only tables and columns that exist in the schema\n        3. Uses proper joins when needed\n        4. Uses appropriate filtering and aggregation\n        5. Is efficient and follows best practices\n        \n        SQL QUERY: \"\"\"\n        return prompt\n    \n    def _parse_llm_response(self, response: str) -> Dict:\n        \"\"\"\n        Parse the LLM response to extract SQL and explanation.\n        \n        Args:\n            response: Raw response from the LLM\n            \n        Returns:\n            Dictionary with SQL query and explanation\n        \"\"\"\n        # Extract SQL from code blocks or SQL prefixed lines\n        sql_pattern = r\"```sql\\s*(.*?)\\s*```\"\n        sql_matches = re.findall(sql_pattern, response, re.DOTALL)\n        \n        if sql_matches:\n            sql = sql_matches[0].strip()\n        else:\n            # Fallback: look for lines that might be SQL\n            sql_lines = []\n            in_sql = False\n            \n            for line in response.split(\"\\n\"):\n                if line.strip().upper().startswith(\"SELECT\") or in_sql:\n                    in_sql = True\n                    if line.strip().endswith(\";\"):\n                        in_sql = False\n                    sql_lines.append(line)\n            \n            sql = \"\\n\".join(sql_lines).strip()\n        \n        # Extract explanation (text after \"EXPLANATION:\" if it exists)\n        explanation_pattern = r\"EXPLANATION:(.*?)(?:$|SQL QUERY:)\"\n        explanation_matches = re.findall(explanation_pattern, response, re.DOTALL)\n        \n        if explanation_matches:\n            explanation = explanation_matches[0].strip()\n        else:\n            # If no explicit explanation section, use everything except the SQL\n            if sql:\n                explanation = response.replace(sql, \"\").strip()\n            else:\n                explanation = \"No explanation provided.\"\n        \n        return {\n            \"sql\": sql,\n            \"explanation\": explanation\n        }\n    \n    def validate_sql(self, sql: str) -> Tuple[bool, str]:\n        \"\"\"\n        Validate SQL query syntax without executing it.\n        \n        Args:\n            sql: SQL query string\n            \n        Returns:\n            Tuple of (is_valid, error_message)\n        \"\"\"\n        if not self.schema_manager.connection:\n            self.schema_manager.connect()\n        \n        try:\n            # Create a cursor and parse the SQL without executing\n            cursor = self.schema_manager.connection.cursor()\n            cursor.execute(f\"EXPLAIN QUERY PLAN {sql}\")\n            cursor.fetchall()  # Fetch results but don't use them\n            return True, \"\"\n        except sqlite3.Error as e:\n            return False, str(e)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-06T15:01:09.139107Z","iopub.execute_input":"2025-05-06T15:01:09.139507Z","iopub.status.idle":"2025-05-06T15:01:09.148751Z","shell.execute_reply.started":"2025-05-06T15:01:09.139491Z","shell.execute_reply":"2025-05-06T15:01:09.148054Z"}},"outputs":[],"execution_count":87},{"cell_type":"code","source":"#####################################################\n# Query Execution\n#####################################################\n\nclass QueryExecutor:\n    \"\"\"Executes SQL queries against the SQLite database and formats results.\"\"\"\n    \n    def __init__(self, schema_manager: DatabaseSchemaManager):\n        \"\"\"\n        Initialize with a schema manager.\n        \n        Args:\n            schema_manager: Database schema manager instance\n        \"\"\"\n        self.schema_manager = schema_manager\n    \n    def execute_query(self, sql: str) -> Dict:\n        \"\"\"\n        Execute a SQL query and return results.\n        \n        Args:\n            sql: SQL query to execute\n            \n        Returns:\n            Dictionary with execution status, results, and metadata\n        \"\"\"\n        if not self.schema_manager.connection:\n            self.schema_manager.connect()\n        \n        try:\n            # Execute query and get results as DataFrame\n            result_df = pd.read_sql_query(sql, self.schema_manager.connection)\n            \n            # Get query execution metadata\n            cursor = self.schema_manager.connection.cursor()\n            cursor.execute(\"EXPLAIN QUERY PLAN \" + sql)\n            query_plan = cursor.fetchall()\n            \n            return {\n                \"status\": \"success\",\n                \"row_count\": len(result_df),\n                \"results\": result_df,\n                \"query_plan\": query_plan\n            }\n        except sqlite3.Error as e:\n            logger.error(f\"Error executing query: {e}\")\n            return {\n                \"status\": \"error\",\n                \"error_message\": str(e),\n                \"results\": None\n            }\n    \n    def format_results(self, execution_result: Dict) -> Dict:\n        \"\"\"\n        Format query execution results for presentation.\n        \n        Args:\n            execution_result: Result from execute_query\n            \n        Returns:\n            Dictionary with formatted results\n        \"\"\"\n        if execution_result[\"status\"] == \"error\":\n            return {\n                \"status\": \"error\",\n                \"message\": f\"Query execution failed: {execution_result['error_message']}\",\n                \"data\": None,\n                \"row_count\": 0,\n                \"columns\": [],\n                \"summary\": {}\n            }\n    \n        result_df = execution_result[\"results\"]\n    \n        # Convert DataFrame to dict records\n        records = result_df.to_dict(orient=\"records\")\n    \n        # Generate summary statistics for numeric columns\n        summary = {}\n        for column in result_df.columns:\n            if np.issubdtype(result_df[column].dtype, np.number):\n                summary[column] = {\n                    \"min\": float(result_df[column].min()),\n                    \"max\": float(result_df[column].max()),\n                    \"mean\": float(result_df[column].mean()),\n                    \"median\": float(result_df[column].median())\n                }\n    \n        return {\n            \"status\": \"success\",\n            \"message\": f\"Query returned {len(records)} rows\",\n            \"data\": records,\n            \"row_count\": len(records),\n            \"columns\": list(result_df.columns),\n            \"summary\": summary\n        }","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-06T15:01:09.149918Z","iopub.execute_input":"2025-05-06T15:01:09.150161Z","iopub.status.idle":"2025-05-06T15:01:09.167219Z","shell.execute_reply.started":"2025-05-06T15:01:09.150146Z","shell.execute_reply":"2025-05-06T15:01:09.166636Z"}},"outputs":[],"execution_count":88},{"cell_type":"code","source":"#####################################################\n# LLM Client\n#####################################################\n\nclass LLMClient:\n    \"\"\"Client for interacting with LLM APIs.\"\"\"\n    \n    def __init__(self, api_key: str = None, api_base: str = None):\n        \"\"\"\n        Initialize LLM client.\n        \n        Args:\n            api_key: API key for the LLM service\n            api_base: Base URL for the LLM API\n        \"\"\"\n        self.api_key = api_key or os.environ.get(\"ANTHROPIC_API_KEY\")\n        self.api_base = api_base or \"https://api.anthropic.com/v1/messages\"\n        \n        # Set up session with retries\n        self.session = requests.Session()\n        retries = Retry(total=3, backoff_factor=0.5, status_forcelist=[502, 503, 504])\n        self.session.mount('https://', HTTPAdapter(max_retries=retries))\n    \n    def generate_sql(self, prompt: str) -> str:\n        \"\"\"\n        Generate SQL using the LLM.\n        \n        Args:\n            prompt: Prompt for SQL generation\n            \n        Returns:\n            Generated SQL and explanation\n        \"\"\"\n        try:\n            # Check if API key is available\n            if not self.api_key:\n                logger.warning(\"No API key provided. Using mock response for testing.\")\n                return self._mock_response(prompt)\n            \n            headers = {\n                \"Content-Type\": \"application/json\",\n                \"X-API-Key\": self.api_key,\n                \"anthropic-version\": \"2023-06-01\"\n            }\n            \n            data = {\n                \"model\": \"claude-3-opus-20240229\",\n                \"max_tokens\": 2000,\n                \"messages\": [{\"role\": \"user\", \"content\": prompt}]\n            }\n            \n            response = self.session.post(\n                self.api_base,\n                headers=headers,\n                json=data,\n                timeout=30\n            )\n            \n            response.raise_for_status()\n            result = response.json()\n            \n            # Extract the text response\n            return result['content'][0]['text']\n            \n        except requests.exceptions.RequestException as e:\n            logger.error(f\"Error calling LLM API: {e}\")\n            return self._mock_response(prompt)\n    \n    def _mock_response(self, prompt: str) -> str:\n        \"\"\"\n        Generate a mock response for testing when API is not available.\n        \n        Args:\n            prompt: Input prompt\n            \n        Returns:\n            Mock response\n        \"\"\"\n        # Extract the question from the prompt\n        question_match = re.search(r\"USER QUESTION: (.*?)(?:\\n|$)\", prompt)\n        if not question_match:\n            return \"Could not parse the question.\"\n        \n        question = question_match.group(1).lower()\n        \n        # Extract table names from the schema section\n        table_matches = re.findall(r\"Table: (\\w+)\", prompt)\n        \n        # Generate a simple mock SQL response based on the question\n        if \"count\" in question:\n            table = table_matches[0] if table_matches else \"users\"\n            mock_sql = f\"SELECT COUNT(*) FROM {table};\"\n        elif \"average\" in question or \"avg\" in question:\n            table = table_matches[0] if table_matches else \"data\"\n            mock_sql = f\"SELECT AVG(value) FROM {table};\"\n        else:\n            table = table_matches[0] if table_matches else \"items\"\n            mock_sql = f\"SELECT * FROM {table} LIMIT 10;\"\n        \n        return f\"\"\"```sql\n{mock_sql}\n```\n\nEXPLANATION:\nThis is a mock SQL query generated for testing purposes when no API key is provided.\nThe query is based on simple pattern matching from your question.\nIn production, this would be replaced with actual LLM-generated SQL.\"\"\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-06T15:01:09.167869Z","iopub.execute_input":"2025-05-06T15:01:09.168105Z","iopub.status.idle":"2025-05-06T15:01:09.184813Z","shell.execute_reply.started":"2025-05-06T15:01:09.168090Z","shell.execute_reply":"2025-05-06T15:01:09.184047Z"}},"outputs":[],"execution_count":89},{"cell_type":"code","source":"#####################################################\n# Result Explainer\n#####################################################\n\nclass ResultExplainer:\n    \"\"\"Explains query results in natural language.\"\"\"\n    \n    def __init__(self, llm_client):\n        \"\"\"\n        Initialize with an LLM client.\n        \n        Args:\n            llm_client: Client for LLM API interaction\n        \"\"\"\n        self.llm_client = llm_client\n    \n    def explain_results(self, user_query: str, sql: str, formatted_results: Dict) -> str:\n        \"\"\"\n        Generate natural language explanation of query results.\n        \n        Args:\n            user_query: Original user query\n            sql: SQL query that was executed\n            formatted_results: Formatted query results\n            \n        Returns:\n            Natural language explanation of results\n        \"\"\"\n        if formatted_results[\"status\"] == \"error\":\n            return f\"The query failed with the following error: {formatted_results['message']}\"\n        \n        # Create prompt for result explanation\n        prompt = self._create_explanation_prompt(user_query, sql, formatted_results)\n        \n        # Get explanation from LLM\n        try:\n            explanation = self.llm_client.generate_sql(prompt)\n            return explanation\n        except Exception as e:\n            logger.error(f\"Error generating explanation: {e}\")\n            # Fallback to basic explanation\n            return self._generate_basic_explanation(formatted_results)\n    \n    def _create_explanation_prompt(self, user_query: str, sql: str, formatted_results: Dict) -> str:\n        \"\"\"\n        Create a prompt for result explanation.\n        \n        Args:\n            user_query: Original user query\n            sql: SQL query that was executed\n            formatted_results: Formatted query results\n            \n        Returns:\n            Formatted prompt for the LLM\n        \"\"\"\n        max_rows = 5\n        data_sample = formatted_results.get(\"data\", [])[:max_rows]\n    \n        prompt = f\"\"\"You are an AI assistant that explains database query results in natural language.\n    Please explain the following query results based on the user's original question.\n    \n    USER QUESTION: {user_query}\n    \n    SQL QUERY:\n    ```sql\n    {sql}\n    ```\n\n    QUERY RESULTS:\n    The query returned {formatted_results.get(\"row_count\", 0)} rows.\n    \n    Sample of the results (first {min(max_rows, len(data_sample))} rows):\n    {json.dumps(data_sample, indent=2)}\n    \n    Column statistics:\n    {json.dumps(formatted_results.get(\"summary\", {}), indent=2)}\n    \n    Please provide a clear, concise explanation of these results in relation to the user's question.\n    Focus on key insights, patterns, and directly answering the user's question.\n    If there are interesting statistics or trends in the data, highlight them.\n    \"\"\"\n        return prompt\n    \n    def _generate_basic_explanation(self, formatted_results: Dict) -> str:\n        \"\"\"\n        Generate a basic explanation when LLM is not available.\n        \n        Args:\n            formatted_results: Formatted query results\n            \n        Returns:\n            Basic explanation of results\n        \"\"\"\n        explanation = f\"The query returned {formatted_results['row_count']} rows with the following columns: \"\n        explanation += \", \".join(formatted_results[\"columns\"])\n        \n        if formatted_results[\"summary\"]:\n            explanation += \"\\n\\nHere are some statistics from the numeric columns:\\n\"\n            for col, stats in formatted_results[\"summary\"].items():\n                explanation += f\"\\n{col}:\"\n                explanation += f\"\\n  - Minimum: {stats['min']}\"\n                explanation += f\"\\n  - Maximum: {stats['max']}\"\n                explanation += f\"\\n  - Mean: {stats['mean']:.2f}\"\n                explanation += f\"\\n  - Median: {stats['median']:.2f}\"\n        \n        return explanation","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-06T15:01:09.186160Z","iopub.execute_input":"2025-05-06T15:01:09.186384Z","iopub.status.idle":"2025-05-06T15:01:09.202781Z","shell.execute_reply.started":"2025-05-06T15:01:09.186369Z","shell.execute_reply":"2025-05-06T15:01:09.202039Z"}},"outputs":[],"execution_count":90},{"cell_type":"code","source":"#####################################################\n# RAG Agent\n#####################################################\n\nclass RAGAgent:\n    \"\"\"Main RAG agent that coordinates all components.\"\"\"\n    \n    def __init__(self, db_path: str, api_key: str = None):\n        \"\"\"\n        Initialize the RAG agent.\n        \n        Args:\n            db_path: Path to the SQLite database\n            api_key: API key for the LLM service\n        \"\"\"\n        # Initialize components\n        self.schema_manager = DatabaseSchemaManager(db_path)\n        self.llm_client = LLMClient(api_key)\n        self.query_processor = QueryProcessor(self.llm_client, self.schema_manager)\n        self.query_executor = QueryExecutor(self.schema_manager)\n        self.result_explainer = ResultExplainer(self.llm_client)\n        \n        # Connect to database\n        self.schema_manager.connect()\n        \n        # Cache the schema\n        self.schema_manager.get_schema()\n        \n        logger.info(\"RAG Agent initialized successfully\")\n    \n    def process_query(self, user_query: str) -> Dict:\n        \"\"\"\n        Process a user query from natural language to results.\n        \n        Args:\n            user_query: Natural language query from the user\n            \n        Returns:\n            Dictionary with all processing results and explanations\n        \"\"\"\n        logger.info(f\"Processing user query: {user_query}\")\n        \n        # Step 1: Generate SQL from natural language\n        query_result = self.query_processor.process_query(user_query)\n        sql = query_result[\"sql\"]\n        sql_explanation = query_result[\"explanation\"]\n        \n        # Step 2: Validate SQL\n        is_valid, error = self.query_processor.validate_sql(sql)\n        \n        if not is_valid:\n            logger.warning(f\"Invalid SQL: {error}\")\n            return {\n                \"status\": \"error\",\n                \"message\": f\"Generated SQL is invalid: {error}\",\n                \"user_query\": user_query,\n                \"sql\": sql,\n                \"sql_explanation\": sql_explanation,\n                \"results\": None,\n                \"result_explanation\": None\n            }\n        \n        # Step 3: Execute SQL\n        execution_result = self.query_executor.execute_query(sql)\n        \n        # Step 4: Format results\n        formatted_results = self.query_executor.format_results(execution_result)\n        \n        # Step 5: Explain results\n        if formatted_results[\"status\"] == \"success\":\n            result_explanation = self.result_explainer.explain_results(\n                user_query, sql, formatted_results\n            )\n        else:\n            result_explanation = formatted_results[\"message\"]\n        \n        return {\n            \"status\": formatted_results[\"status\"],\n            \"message\": formatted_results[\"message\"],\n            \"user_query\": user_query,\n            \"sql\": sql,\n            \"sql_explanation\": sql_explanation,\n            \"results\": formatted_results[\"data\"] if formatted_results[\"status\"] == \"success\" else None,\n            \"columns\": formatted_results.get(\"columns\", []),\n            \"summary\": formatted_results.get(\"summary\", {}),\n            \"result_explanation\": result_explanation\n        }\n    \n    def close(self):\n        \"\"\"Clean up resources.\"\"\"\n        self.schema_manager.close()\n        logger.info(\"RAG Agent resources cleaned up\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-06T15:01:09.203547Z","iopub.execute_input":"2025-05-06T15:01:09.203752Z","iopub.status.idle":"2025-05-06T15:01:09.220756Z","shell.execute_reply.started":"2025-05-06T15:01:09.203737Z","shell.execute_reply":"2025-05-06T15:01:09.220118Z"}},"outputs":[],"execution_count":91},{"cell_type":"code","source":"#####################################################\n# Example Usage\n#####################################################\n\ndef example_usage():\n    \"\"\"Example usage of the RAG agent.\"\"\"\n    \n    # Path to your SQLite database (adjust as needed)\n    db_path = \"/kaggle/input/cargill/cargill.db\"\n    \n    # Initialize the RAG agent\n    agent = RAGAgent(db_path,api_key=\"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\")\n    \n    # Example query\n    user_query = \"Which countries have the most customers?\"\n    \n    # Process the query\n    result = agent.process_query(user_query)\n    \n    # Print the results\n    print(f\"User Query: {result['user_query']}\\n\")\n    print(f\"Generated SQL:\\n{result['sql']}\\n\")\n    print(f\"SQL Explanation:\\n{result['sql_explanation']}\\n\")\n    \n    if result['status'] == 'success':\n        print(f\"Results:\\n{pd.DataFrame(result['results'])}\\n\")\n        print(f\"Result Explanation:\\n{result['result_explanation']}\\n\")\n    else:\n        print(f\"Error: {result['message']}\\n\")\n    \n    # Clean up\n    agent.close()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-06T15:01:09.221471Z","iopub.execute_input":"2025-05-06T15:01:09.221649Z","iopub.status.idle":"2025-05-06T15:01:09.237835Z","shell.execute_reply.started":"2025-05-06T15:01:09.221627Z","shell.execute_reply":"2025-05-06T15:01:09.237243Z"}},"outputs":[],"execution_count":92},{"cell_type":"code","source":"if __name__ == \"__main__\":\n    example_usage()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-06T15:01:09.238451Z","iopub.execute_input":"2025-05-06T15:01:09.238633Z","iopub.status.idle":"2025-05-06T15:01:28.901439Z","shell.execute_reply.started":"2025-05-06T15:01:09.238619Z","shell.execute_reply":"2025-05-06T15:01:28.900817Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1458: RuntimeWarning: invalid value encountered in greater\n  has_large_values = (abs_vals > 1e6).any()\n/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1459: RuntimeWarning: invalid value encountered in less\n  has_small_values = ((abs_vals < 10 ** (-self.digits)) & (abs_vals > 0)).any()\n/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1459: RuntimeWarning: invalid value encountered in greater\n  has_small_values = ((abs_vals < 10 ** (-self.digits)) & (abs_vals > 0)).any()\n","output_type":"stream"},{"name":"stdout","text":"User Query: Which countries have the most customers?\n\nGenerated SQL:\nSELECT c.country, COUNT(*) AS num_customers\nFROM customer c\nGROUP BY c.country\nORDER BY num_customers DESC\nLIMIT 3;\n\nSQL Explanation:\nTo find the countries with the most customers, we need to:\n\n1. Select from the `customer` table since that contains the country for each customer\n2. Group the results by the `country` column to get a count for each distinct country value \n3. SELECT the `country` and use COUNT(*) to count the number of customers for each country\n4. ORDER BY the counted `num_customers` in DESCending order to put the countries with the most customers first\n5. Use LIMIT 3 to return just the top 3 countries with the most customers\n\nThis query efficiently aggregates the data by country, counts the customers per country, orders it to put the highest counts first, and limits the result to the top 3 countries.\n\nThe key aspects are:\n- Selecting from the correct `customer` table that has the country data\n- Grouping by `country` to aggregate customers per country\n- Ordering descending by the counted number of customers \n- Limiting to just the top 3 results\n\nThis will show us the 3 countries that have the highest number of customers in the database.\n\nResults:\n         country  num_customers\n0         Brazil             14\n1         Canada             13\n2  United States             11\n\nResult Explanation:\n```sql\nSELECT COUNT(*) FROM users;\n```\n\nEXPLANATION:\nThis is a mock SQL query generated for testing purposes when no API key is provided.\nThe query is based on simple pattern matching from your question.\nIn production, this would be replaced with actual LLM-generated SQL.\n\n","output_type":"stream"}],"execution_count":93},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}